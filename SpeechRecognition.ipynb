{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_io as tfio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_RATIO = 0.1\n",
    "URL_PATH = \"https://www.openslr.org/resources/83/\"\n",
    "\n",
    "zip_files = {\n",
    "    0: \"irish_english_male.zip\",\n",
    "    1: \"midlands_english_female.zip\",\n",
    "    2: \"midlands_english_male.zip\",\n",
    "    3: \"northern_english_female.zip\",\n",
    "    4: \"northern_english_male.zip\",\n",
    "    5: \"scottish_english_female.zip\",\n",
    "    6: \"scottish_english_male.zip\",\n",
    "    7: \"southern_english_female.zip\",\n",
    "    8: \"southern_english_male.zip\",\n",
    "    9: \"welsh_english_female.zip\",\n",
    "    10: \"welsh_english_male.zip\",\n",
    "}\n",
    "\n",
    "gender_agnostic_categories = [\n",
    "    \"ir\",  # Irish\n",
    "    \"mi\",  # Midlands\n",
    "    \"no\",  # Northern\n",
    "    \"sc\",  # Scottish\n",
    "    \"so\",  # Southern\n",
    "    \"we\",  # Welsh\n",
    "]\n",
    "class_names = [\n",
    "    \"Irish\",\n",
    "    \"Midlands\",\n",
    "    \"Northern\",\n",
    "    \"Scottish\",\n",
    "    \"Southern\",\n",
    "    \"Welsh\",\n",
    "    \"Not a speech\",\n",
    "]\n",
    "\n",
    "CACHE_DIR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(SEED)\n",
    "\n",
    "\n",
    "DATASET_DESTINATION = os.path.join(CACHE_DIR if CACHE_DIR else \"~/.keras/\", \"datasets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.openslr.org/resources/83/irish_english_male.zip\n",
      "164531638/164531638 [==============================] - 220s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/midlands_english_female.zip\n",
      "103085118/103085118 [==============================] - 147s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/midlands_english_male.zip\n",
      "166833961/166833961 [==============================] - 233s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/northern_english_female.zip\n",
      "314983063/314983063 [==============================] - 441s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/northern_english_male.zip\n",
      "817772034/817772034 [==============================] - 1143s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/scottish_english_female.zip\n",
      "351443880/351443880 [==============================] - 478s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/scottish_english_male.zip\n",
      "620254118/620254118 [==============================] - 840s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/southern_english_female.zip\n",
      "1636701939/1636701939 [==============================] - 2266s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/southern_english_male.zip\n",
      "1700955740/1700955740 [==============================] - 2384s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/welsh_english_female.zip\n",
      "595683538/595683538 [==============================] - 797s 1us/step\n",
      "Downloading data from https://www.openslr.org/resources/83/welsh_english_male.zip\n",
      "757645790/757645790 [==============================] - 1046s 1us/step\n"
     ]
    }
   ],
   "source": [
    "line_index_file = keras.utils.get_file(fname=\"line_index_file\", origin=URL_PATH + \"line_index_all.csv\")\n",
    "\n",
    "for i in zip_files:\n",
    "    fname = zip_files[i].split(\".\")[0]\n",
    "    url = URL_PATH + zip_files[i]\n",
    "    zip_file = keras.utils.get_file(fname=fname, origin=url, extract=True)\n",
    "    os.remove(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wef_12484_01482829612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wef_12484_01345932698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wef_12484_00999757777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wef_12484_00036278823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wef_12484_00458512623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17872</th>\n",
       "      <td>som_06592_00422956963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17873</th>\n",
       "      <td>som_06136_01223762368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17874</th>\n",
       "      <td>som_03349_00420644955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>som_03397_02006793154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>som_09799_00573643901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17877 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename\n",
       "0       wef_12484_01482829612\n",
       "1       wef_12484_01345932698\n",
       "2       wef_12484_00999757777\n",
       "3       wef_12484_00036278823\n",
       "4       wef_12484_00458512623\n",
       "...                       ...\n",
       "17872   som_06592_00422956963\n",
       "17873   som_06136_01223762368\n",
       "17874   som_03349_00420644955\n",
       "17875   som_03397_02006793154\n",
       "17876   som_09799_00573643901\n",
       "\n",
       "[17877 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(line_index_file, names=[\"id\", \"filename\", \"transcript\"], usecols=[\"filename\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Data Science\\ml\\notebooks\\datasets\\som_0385...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Data Science\\ml\\notebooks\\datasets\\som_0431...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\Data Science\\ml\\notebooks\\datasets\\sof_0613...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\Data Science\\ml\\notebooks\\datasets\\som_0248...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\Data Science\\ml\\notebooks\\datasets\\nom_0613...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label\n",
       "0  D:\\Data Science\\ml\\notebooks\\datasets\\som_0385...      4\n",
       "1  D:\\Data Science\\ml\\notebooks\\datasets\\som_0431...      4\n",
       "2  D:\\Data Science\\ml\\notebooks\\datasets\\sof_0613...      4\n",
       "3  D:\\Data Science\\ml\\notebooks\\datasets\\som_0248...      4\n",
       "4  D:\\Data Science\\ml\\notebooks\\datasets\\nom_0613...      2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_dataframe(dataframe):\n",
    "    # Remove leading space in filename column\n",
    "    dataframe[\"filename\"] = dataframe.apply(lambda row: row[\"filename\"].strip(), axis=1)\n",
    "\n",
    "    # Create gender agnostic labels based on the filename first 2 letters\n",
    "    dataframe[\"label\"] = dataframe.apply(\n",
    "        lambda row: gender_agnostic_categories.index(row[\"filename\"][:2]), axis=1\n",
    "    )\n",
    "\n",
    "    # Add the file path to the name\n",
    "    dataframe[\"filename\"] = dataframe.apply(\n",
    "        lambda row: os.path.join(DATASET_DESTINATION, row[\"filename\"] + \".wav\"), axis=1\n",
    "    )\n",
    "\n",
    "    # Shuffle the samples\n",
    "    dataframe = dataframe.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "data = preprocess_dataframe(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 16089 training samples & 1788 validation ones\n"
     ]
    }
   ],
   "source": [
    "split = int(len(data) * (1 - VALIDATION_RATIO))\n",
    "train_df = data[:split]\n",
    "valid_df = data[split:]\n",
    "\n",
    "print( f\"We have {train_df.shape[0]} training samples & {valid_df.shape[0]} validation ones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19304\\1715577312.py\", line 24, in None  *\n        lambda x, y: filepath_to_embeddings(x, y)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19304\\1715577312.py\", line 11, in filepath_to_embeddings  *\n        audio_wav = load_16k_audio(filename)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19304\\1715577312.py\", line 6, in load_16k_audio  *\n        audio_wav = tfio.audio.resample(audio_wav, rate_in=sample_rate, rate_out=16000)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 462, in resample  **\n        value = tf.vectorized_map(f, input)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['c:\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['c:\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Data Science\\ml\\Notebooks\\SpeechRecognition.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x, y: filepath_to_embeddings(x, y),num_parallel_calls\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE,)\u001b[39m.\u001b[39munbatch()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mbatch(batch_size)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m train_ds \u001b[39m=\u001b[39m dataframe_to_dataset(train_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m valid_ds \u001b[39m=\u001b[39m dataframe_to_dataset(valid_df)\n",
      "\u001b[1;32md:\\Data Science\\ml\\Notebooks\\SpeechRecognition.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataframe_to_dataset\u001b[39m(dataframe, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((dataframe[\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m], dataframe[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x, y: filepath_to_embeddings(x, y),num_parallel_calls\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mAUTOTUNE,)\u001b[39m.\u001b[39munbatch()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/ml/Notebooks/SpeechRecognition.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mbatch(batch_size)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2204\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2202\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39m, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2204\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2205\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2206\u001b[0m       map_func,\n\u001b[0;32m   2207\u001b[0m       num_parallel_calls,\n\u001b[0;32m   2208\u001b[0m       deterministic,\n\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   2210\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5441\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m   5440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m-> 5441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5442\u001b[0m     map_func,\n\u001b[0;32m   5443\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m   5444\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m   5445\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m   5446\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5447\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemepcn5aw.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x, y: ag__\u001b[39m.\u001b[39;49mwith_function_scope(\u001b[39mlambda\u001b[39;49;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(filepath_to_embeddings, (x, y), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39;49m\u001b[39mlscope\u001b[39;49m\u001b[39m'\u001b[39;49m, ag__\u001b[39m.\u001b[39;49mSTD)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m FunctionScope(\u001b[39m'\u001b[39m\u001b[39mlambda_\u001b[39m\u001b[39m'\u001b[39m, scope_name, options) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m--> 113\u001b[0m   \u001b[39mreturn\u001b[39;00m thunk(scope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemepcn5aw.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x, y: ag__\u001b[39m.\u001b[39mwith_function_scope(\u001b[39mlambda\u001b[39;00m lscope: ag__\u001b[39m.\u001b[39;49mconverted_call(filepath_to_embeddings, (x, y), \u001b[39mNone\u001b[39;49;00m, lscope), \u001b[39m'\u001b[39m\u001b[39mlscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filej8xjyx3m.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__filepath_to_embeddings\u001b[1;34m(filename, label)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m audio_wav \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(load_16k_audio), (ag__\u001b[39m.\u001b[39;49mld(filename),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     11\u001b[0m (scores, embeddings, _) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(yamnet_model), (ag__\u001b[39m.\u001b[39mld(audio_wav),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m embeddings_num \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(embeddings),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filej1a5kn1g.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__load_16k_audio\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     12\u001b[0m audio_wav \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39msqueeze, (ag__\u001b[39m.\u001b[39mld(audio_wav),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), fscope)\n\u001b[0;32m     13\u001b[0m sample_rate \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcast, (ag__\u001b[39m.\u001b[39mld(sample_rate),), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mint64), fscope)\n\u001b[1;32m---> 14\u001b[0m audio_wav \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tfio)\u001b[39m.\u001b[39;49maudio\u001b[39m.\u001b[39;49mresample, (ag__\u001b[39m.\u001b[39;49mld(audio_wav),), \u001b[39mdict\u001b[39;49m(rate_in\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(sample_rate), rate_out\u001b[39m=\u001b[39;49m\u001b[39m16000\u001b[39;49m), fscope)\n\u001b[0;32m     15\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:462\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(input, rate_in, rate_out, name)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(i):\n\u001b[0;32m    458\u001b[0m     \u001b[39mreturn\u001b[39;00m core_ops\u001b[39m.\u001b[39mio_audio_resample(\n\u001b[0;32m    459\u001b[0m         i, rate_in\u001b[39m=\u001b[39mrate_in, rate_out\u001b[39m=\u001b[39mrate_out, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    460\u001b[0m     )\n\u001b[1;32m--> 462\u001b[0m value \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mvectorized_map(f, \u001b[39minput\u001b[39;49m)\n\u001b[0;32m    464\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg1\u001b[39m():\n\u001b[0;32m    465\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39msqueeze(value, [\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:565\u001b[0m, in \u001b[0;36mvectorized_map\u001b[1;34m(fn, elems, fallback_to_while_loop, warn)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    563\u001b[0m   batch_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(static_first_dims)\n\u001b[1;32m--> 565\u001b[0m \u001b[39mreturn\u001b[39;00m pfor(\n\u001b[0;32m    566\u001b[0m     loop_fn,\n\u001b[0;32m    567\u001b[0m     batch_size,\n\u001b[0;32m    568\u001b[0m     fallback_to_while_loop\u001b[39m=\u001b[39;49mfallback_to_while_loop,\n\u001b[0;32m    569\u001b[0m     warn\u001b[39m=\u001b[39;49mwarn)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:214\u001b[0m, in \u001b[0;36mpfor\u001b[1;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, warn)\u001b[0m\n\u001b[0;32m    211\u001b[0m     def_function\u001b[39m.\u001b[39mrun_functions_eagerly(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    212\u001b[0m   f \u001b[39m=\u001b[39m def_function\u001b[39m.\u001b[39mfunction(f)\n\u001b[1;32m--> 214\u001b[0m outputs \u001b[39m=\u001b[39m f()\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m functions_run_eagerly \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m   def_function\u001b[39m.\u001b[39mrun_functions_eagerly(functions_run_eagerly)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:193\u001b[0m, in \u001b[0;36mpfor.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m():\n\u001b[1;32m--> 193\u001b[0m   \u001b[39mreturn\u001b[39;00m _pfor_impl(\n\u001b[0;32m    194\u001b[0m       loop_fn,\n\u001b[0;32m    195\u001b[0m       iters,\n\u001b[0;32m    196\u001b[0m       fallback_to_while_loop\u001b[39m=\u001b[39;49mfallback_to_while_loop,\n\u001b[0;32m    197\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m    198\u001b[0m       warn\u001b[39m=\u001b[39;49mwarn)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:295\u001b[0m, in \u001b[0;36m_pfor_impl\u001b[1;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, pfor_config, warn)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[39massert\u001b[39;00m pfor_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     f \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(loop_fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx())\n\u001b[1;32m--> 295\u001b[0m     loop_fn_outputs \u001b[39m=\u001b[39m f(loop_var)\n\u001b[0;32m    296\u001b[0m   loop_fn_output_tensors \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(_composite_to_tensors,\n\u001b[0;32m    297\u001b[0m                                               loop_fn_outputs)\n\u001b[0;32m    299\u001b[0m \u001b[39m# Convert outputs to Tensor if needed.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py:546\u001b[0m, in \u001b[0;36mvectorized_map.<locals>.loop_fn\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloop_fn\u001b[39m(i):\n\u001b[0;32m    544\u001b[0m   gathered_elems \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    545\u001b[0m       \u001b[39mlambda\u001b[39;00m x: _gather_from_tensor_or_composite(x, i), elems)\n\u001b[1;32m--> 546\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(gathered_elems)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:458\u001b[0m, in \u001b[0;36mresample.<locals>.f\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(i):\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m core_ops\u001b[39m.\u001b[39;49mio_audio_resample(\n\u001b[0;32m    459\u001b[0m         i, rate_in\u001b[39m=\u001b[39mrate_in, rate_out\u001b[39m=\u001b[39mrate_out, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    460\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:88\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, attrb)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attrb):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load(), attrb)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:84\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mod \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mod \u001b[39m=\u001b[39m _load_library(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_library)\n\u001b[0;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mod\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:69\u001b[0m, in \u001b[0;36m_load_library\u001b[1;34m(filename, lib)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mNotFoundError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     68\u001b[0m         errs\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(e))\n\u001b[1;32m---> 69\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39munable to open file: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m, from paths: \u001b[39m\u001b[39m{\u001b[39;00mfilenames\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mcaused by: \u001b[39m\u001b[39m{\u001b[39;00merrs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19304\\1715577312.py\", line 24, in None  *\n        lambda x, y: filepath_to_embeddings(x, y)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19304\\1715577312.py\", line 11, in filepath_to_embeddings  *\n        audio_wav = load_16k_audio(filename)\n    File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19304\\1715577312.py\", line 6, in load_16k_audio  *\n        audio_wav = tfio.audio.resample(audio_wav, rate_in=sample_rate, rate_out=16000)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 462, in resample  **\n        value = tf.vectorized_map(f, input)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"c:\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['c:\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['c:\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n"
     ]
    }
   ],
   "source": [
    "def load_16k_audio(filename):\n",
    "    file_content = tf.io.read_file(filename)\n",
    "    audio_wav, sample_rate = tf.audio.decode_wav(file_content, desired_channels=1)\n",
    "    audio_wav = tf.squeeze(audio_wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    audio_wav = tfio.audio.resample(audio_wav, rate_in=sample_rate, rate_out=16000)\n",
    "\n",
    "    return audio_wav\n",
    "\n",
    "def filepath_to_embeddings(filename, label):\n",
    "    audio_wav = load_16k_audio(filename)\n",
    "    scores, embeddings, _ = yamnet_model(audio_wav)\n",
    "\n",
    "    embeddings_num = tf.shape(embeddings)[0]\n",
    "    labels = tf.repeat(label, embeddings_num)\n",
    "    #changing labels for time-slots that are not speech into new category 'other'\n",
    "    labels = tf.where(tf.argmax(scores, axis=1) == 0, label, len(class_names) - 1)\n",
    "\n",
    "    return (embeddings, tf.one_hot(labels, len(class_names)))\n",
    "\n",
    "def dataframe_to_dataset(dataframe, batch_size=64):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataframe[\"filename\"], dataframe[\"label\"]))\n",
    "\n",
    "    dataset = dataset.map(lambda x, y: filepath_to_embeddings(x, y),num_parallel_calls=tf.data.experimental.AUTOTUNE,).unbatch()\n",
    "\n",
    "    return dataset.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_df)\n",
    "valid_ds = dataframe_to_dataset(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
